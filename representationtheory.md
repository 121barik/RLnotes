# Representation Theory

## Algebraic Topology and Neural networks
* https://arxiv.org/pdf/1802.04443.pdf
* Can use algebraic topology as a measure of data complexity
* Intuitively the more holes and clusters are in a dataset, the harder it is to learn
* With more layers in a network it becomes easier to learn on datasets with more holes so this work aims to to characterize different neural net architectures using persistent homology
* Final contribution is an algorithm called topological archtecture selection which uses this insight on Open ML benchmark datasets
* A, B are homeomorphic and f is their homomorphism if there exists f: A -> b and f^-1 : B -> A
* The power of topology is that it can differentiate between two spaces while ignoring certain irrelevant features like rotation, translation and curvature
* Algebraic topology is about showing how two spaces are equivalent or not by first mapping them to algebraic constructs like groups and chains
* 

## State representation learning

## OSS projects
* https://github.com/dlfivefifty/RepresentationTheory.jl
* https://github.com/gbarsih/Representations-in-Robotics
* TODO: more stuff on geometric deep learning